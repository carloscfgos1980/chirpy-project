# 5.1 Storage
Arguably the most important part of your typical web application is the storage of data. It would be pretty useless if each time you logged into your account on YouTube, Twitter or GitHub, all of your subscriptions, tweets, or repositories were gone.

Memory vs. Disk
When you run a program on your computer (like our HTTP server), the program is loaded into memory. Memory is a lot like a scratch pad. It's fast, but it's not permanent. If the program terminates or restarts, the data in memory is lost.

When you're building a web server, any data you store in memory (in your program's variables) is lost when the server is restarted. Any important data needs to be saved to disk via the file system.

Option 1: Raw Files
We could take our user's data, serialize it to JSON, and save it to disk in .json files (or any other format for that matter). It's simple, and will even work for small applications. Trouble is, it will run into problems fast:

Concurrency: If two requests try to write to the same file at the same time, you'll get overwritten data.
Scalability: It's not efficient to read and write large files to disk for every request.
Complexity: You'll have to write a lot of code to manage the files, and the chances of bugs are high.
Option 2: a Database
At the end of the day, a database technology like MySQL, PostgreSQL, or MongoDB "just" writes files to disk. The difference is that they also come with all the fancy code and algorithms that make managing those files efficient and safe. In the case of a SQL database, the files are abstracted away from us entirely. You just write SQL queries and let the DB handle the rest.

We will be using option 2: PostgreSQL. It's a production-ready, open-source SQL database. It's a great choice for many web applications, and as a back-end engineer, it might be the single most important database to be familiar with.

# 5.2 Goose Migrations

Goose is a database migration tool written in Go. It runs migrations from a set of SQL files, making it a perfect fit for this project (we wanna stay close to the raw SQL).

What Is a Migration?
A migration is just a set of changes to your database table. You can have as many migrations as needed as your requirements change over time. For example, one migration might create a new table, one might delete a column, and one might add 2 new columns.

An "up" migration moves the state of the database from its current schema to the schema that you want. So, to get a "blank" database to the state it needs to be ready to run your application, you run all the "up" migrations.

If something breaks, you can run one of the "down" migrations to revert the database to a previous state. "Down" migrations are also used if you need to reset a local testing database to a known state.

Users
Our API needs to support the standard CRUD operations for "users" - the people logging into and using our application.

Assignment
Install Goose.
Goose is just a command line tool that happens to be written in Go. I recommend installing it using go install:

go install github.com/pressly/goose/v3/cmd/goose@latest

Run goose -version to make sure it's installed correctly.

Create a users migration in a new sql/schema directory.
A "migration" in Goose is just a .sql file with some SQL queries and some special comments. Our first migration should just create a users table. The simplest format for these files is:

number_name.sql

For example, I created a file in sql/schema called 001_users.sql with the following contents:

-- +goose Up
CREATE TABLE ...

-- +goose Down
DROP TABLE users;

Write out the CREATE TABLE statement in full, I left it blank for you to fill in. A user should have 4 fields:

id: a UUID that will serve as the primary key
created_at: a TIMESTAMP that can not be null
updated_at: a TIMESTAMP that can not be null
email: TEXT that can not be null and must be unique
The -- +goose Up and -- +goose Down comments are required. They tell Goose how to run the migration in each direction.

Get your connection string. A connection string is just a URL with all of the information needed to connect to a database. The format is:
protocol://username:password@host:port/database

Here are examples:

macOS (no password, your username): postgres://wagslane:@localhost:5432/chirpy
Linux (password from last lesson, postgres user): postgres://postgres:postgres@localhost:5432/chirpy
Test your connection string by running psql, for example:

psql "postgres://wagslane:@localhost:5432/chirpy"

It should connect you to the chirpy database directly. If it's working, great. exit out of psql and save the connection string.

Run the up migration.
cd into the sql/schema directory and run:

goose postgres <connection_string> up

example

goose postgres "postgres://wagslane:@localhost:5432/chirpy" up

Run your migration! Make sure it works by using psql to find your newly created users table:

psql chirpy
\dt

Run the down migration to make sure it works (it should just drop the table).
When you're satisfied, run the up migration again to recreate the table.


psql "postgres://carlosinfante:@localhost:5432/chirpy1"

Note: I had to install postgres again coz I was having an issue. I thing I was already having postgres running in the background!


# 5.3 SQLC

SQLC is an amazing Go program that generates Go code from SQL queries. It's not exactly an ORM, but rather a tool that makes working with raw SQL easy and type-safe.

We will be using Goose to manage our database migrations (the schema). We'll be using SQLC to generate Go code that our application can use to interact with the database (run queries).

https://sqlc.dev

# 5.4 

1. Install 
go install github.com/sqlc-dev/sqlc/cmd/sqlc@latest

2. create a file (sqlc.yaml) in the the server root with this code:
version: "2"
sql:

- schema: "sql/schema"
    queries: "sql/queries"
    engine: "postgresql"
    gen:
      go:
        out: "internal/database"

3. Create a schema in the following path/directory:
sq/schema/001_users.sql


-- +goose Up
CREATE TABLE users (
    id UUID PRIMARY KEY,
    created_at TIMESTAMP NOT NULL,
    updated_at TIMESTAMP NOT NULL,
    email TEXT NOT NULL UNIQUE
);

-- +goose Down
DROP TABLE users;

4. Create a query in the following path/directory:
sq/queries/001_users.sql
VALUES (
    gen_random_uuid(),
    NOW(),
    NOW(),
    $1
)
RETURNING *;

We'll be using UUIDs for ID values, so you can use gen_random_uuid() to generate a new UUID.
The created_at and updated_at fields should be set to the current timestamp. In Postgres, you can use NOW() to get the current timestamp.
The email should be passed in by our application. Use $1 to represent the first parameter passed into the query. (in future queries, we'll use $2, $3, etc. for additional parameters)
The :one at the end of the query name tells SQLC that we expect to get back a single row (the created user).

5. Generate the code:
sqlc generate

6. Add UUID package:
go get github.com/google/uuid

7. Add this import to the top of your main.go file:

import _ "github.com/lib/pq"

This is one of my least favorite things working with SQL in Go currently. You have to import the driver, but you don't use it directly anywhere in your code. The underscore tells Go that you're importing it for its side effects, not because you need to use it.

8. Create a .env file in the root of your project
DB_URL="YOUR_CONNECTION_STRING_HERE"

9. Add .gitignore with .env directory and out file

10. package to handle .env:
go get github.com/joho/godotenv

11. Add a value as a pointer to the apiConfig:
type apiConfig struct {
 fileserverHits atomic.Int32
 db             *database.Queries
}

12. Use to load the database:
 godotenv.Load()
 dbURL := os.Getenv("DB_URL")
 if dbURL == "" {
  log.Fatal("DB_URL must be set")
 }

13. Open the connection
 dbConn, err := sql.Open("postgres", dbURL)
 if err != nil {
  log.Fatalf("Error opening database: %s", err)
 }
 dbQueries := database.New(dbConn)

 apiCfg := apiConfig{
  fileserverHits: atomic.Int32{},
  db:             dbQueries,
 }

# 5.5 Create a User
1. <handler_user_create.go> Function to handler create user:

1.1 Create a type struct in the global scope for the user values to store in database
type User struct {
 ID        uuid.UUID `json:"id"`
 CreatedAt time.Time `json:"created_at"`
 UpdatedAt time.Time `json:"updated_at"`
 Email     string    `json:"email"`
}

func (cfg *apiConfig) handlerUsersCreate(w http.ResponseWriter, r*http.Request) {
1.2 Create a type struct to store the requet's body (email)
 type parameters struct {
  Email string `json:"email"`
 }

 1.3 type response, in this case it qould be the user I created
 type response struct {
  User
 }

1.4 Convert to go the requet's body
 decoder := json.NewDecoder(r.Body)
 params := parameters{}
 err := decoder.Decode(&params)
 if err != nil {
  respondWithError(w, http.StatusInternalServerError, "Couldn't decode parameters", err)
  return
 }

1.5 Save into the databse and populate the user
 user, err := cfg.db.CreateUser(r.Context(), params.Email)
 if err != nil {
  respondWithError(w, http.StatusInternalServerError, "Couldn't create user", err)
  return
 }

1.6 response with created (201) and the body would be the user
 respondWithJSON(w, http.StatusCreated, response{
  User: User{
   ID:        user.ID,
   CreatedAt: user.CreatedAt,
   UpdatedAt: user.UpdatedAt,
   Email:     user.Email,
  },
 })
}

2. Update the POST /admin/reset endpoint to delete all users in the database (but don't mess with the schema). You'll need a new SQLC query for this. Add a new value to your .env file called PLATFORM and set it equal to "dev". Read it into your apiConfig. If PLATFORM is not equal to "dev", this endpoint should return a 403 Forbidden. This ensures that this extremely dangerous endpoint can only be accessed in a local development environment.


2.1 <sql/queries/reset.sql>
-- name: Reset :exec
DELETE FROM users;

2.2 method to reset the account of visit to the site and to delete de user table. Before do that is necessary to check a condiction (platform = "dev"):
func (cfg *apiConfig) handlerReset(w http.ResponseWriter, r*http.Request) {
 if cfg.platform != "dev" {
  w.WriteHeader(http.StatusForbidden)
  w.Write([]byte("Reset is only allowed in dev environment."))
  return
 }

 cfg.fileserverHits.Store(0)
 err := cfg.db.Reset(r.Context())
 if err != nil {
  w.WriteHeader(http.StatusInternalServerError)
  w.Write([]byte("Failed to reset the database: " + err.Error()))
  return
 }
 w.WriteHeader(http.StatusOK)
 w.Write([]byte("Hits reset to 0 and database reset to initial state."))
}




<IMPORTANT!> To run the goose migration
cd sql/schema
goose postgres postgres://carlosinfante:@localhost:5432/chirpy1 up
goose postgres postgres://carlosinfante:@localhost:5432/chirpy1 down

<Note> 
I was struggling for a long time coz I had a wrong key in the request in Postman. I was using "body", instead of "email". It all works fine!

# 5.6 Create chirps

1. <sql/schema/002_chirps.sql>. Create schema
-- +goose Up
CREATE TABLE chirps (
    id UUID PRIMARY KEY,
    created_at TIMESTAMP NOT NULL,
    updated_at TIMESTAMP NOT NULL,
    body TEXT NOT NULL,
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE
);

-- +goose Down
DROP TABLE chirps;

2. <sql/queries/chirps.sql>. Create query for chirps table:
-- name: CreateChirp :one
INSERT INTO chirps (id, created_at, updated_at, body, user_id)
VALUES (
    gen_random_uuid(),
    NOW(),
    NOW(),
    $1,
    $2
)
RETURNING *;

3. Create the table in database:
in the terminal in "server" directory:
cd sql/schema

goose postgres postgres://carlosinfante:@localhost:5432/chirpy1 up

4. Generate code to handle the method for creating a "chirp". In "server" a root directory:
sqlc generate

5. <habler_chirps_create.go>
Here I had to adapt to that I had before. I use to auxiliar functions:

5.1 one to "clean" the text
func getCleanedBody(body string, badWords map[string]struct{}) string {
 words := strings.Split(body, " ")
 for i, word := range words {
  loweredWord := strings.ToLower(word)
  if _, ok := badWords[loweredWord]; ok {
   words[i] = "****"
  }
 }
 cleaned := strings.Join(words, " ")
 return cleaned
}

5.2 The other one to validate the text (no longer than 140 characters)
func validateChirp(body string) (string, error) {
 const maxChirpLength = 140
 if len(body) > maxChirpLength {
  return "", errors.New("Chirp is too long")
 }

 badWords := map[string]struct{}{
  "kerfuffle": {},
  "sharbert":  {},
  "fornax":    {},
 }
 cleaned := getCleanedBody(body, badWords)
 return cleaned, nil
}

5.3 Method to create a chirp


func (cfg *apiConfig) handlerChirpsCreate(w http.ResponseWriter, r*http.Request) {

// parameters struct to save in go the json data coming from the request
 type parameters struct {
  Body   string    `json:"body"`
  UserID uuid.UUID `json:"user_id"`
 }

// Decode to go
 decoder := json.NewDecoder(r.Body)
 params := parameters{}
 err := decoder.Decode(&params)
 if err != nil {
  respondWithError(w, http.StatusInternalServerError, "Couldn't decode parameters", err)
  return
 }
 log.Printf("Validating chirp: %s", params.Body)

// call the "validateChirp" wich math the lenght and clean the text
 cleaned, err := validateChirp(params.Body)
 if err != nil {
  respondWithError(w, http.StatusBadRequest, "Invalid chirp", err)
  return
 }

// create the chirp in database
 chirp, err := cfg.db.CreateChirp(r.Context(), database.CreateChirpParams{
  Body:   cleaned,
  UserID: params.UserID,
 })
 if err != nil {
  respondWithError(w, http.StatusInternalServerError, "Couldn't create chirp", err)
  return
 }

// response with created status and the body is the created chirp
 respondWithJSON(w, http.StatusCreated, Chirp{
  ID:        chirp.ID,
  CreatedAt: chirp.CreatedAt,
  UpdatedAt: chirp.UpdatedAt,
  Body:      chirp.Body,
  UserID:    chirp.UserID,
 })
}
